{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sklearn decision tree classifier: 1.0\n",
      "MSE of sklearn decision tree classifier: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train a decision tree classifier\u001b[39;00m\n\u001b[0;32m     25\u001b[0m my_clf \u001b[38;5;241m=\u001b[39m MyDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m my_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m my_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of my decision tree classifier:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:11\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X, y, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:30\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     27\u001b[0m left_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m     28\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m>\u001b[39m threshold\n\u001b[1;32m---> 30\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[left_indices], y[left_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[right_indices], y[right_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_index\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_idx,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: threshold,\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: left_subtree,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: right_subtree}\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:30\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     27\u001b[0m left_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m     28\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m>\u001b[39m threshold\n\u001b[1;32m---> 30\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[left_indices], y[left_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[right_indices], y[right_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_index\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_idx,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: threshold,\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: left_subtree,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: right_subtree}\n",
      "    \u001b[1;31m[... skipping similar frames: DecisionTreeClassifier._build_tree at line 30 (1 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:30\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     27\u001b[0m left_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m     28\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m>\u001b[39m threshold\n\u001b[1;32m---> 30\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[left_indices], y[left_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[right_indices], y[right_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_index\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_idx,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: threshold,\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: left_subtree,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: right_subtree}\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:31\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     28\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m X[:, feature_idx] \u001b[38;5;241m>\u001b[39m threshold\n\u001b[0;32m     30\u001b[0m left_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[left_indices], y[left_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m right_subtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tree(X[right_indices], y[right_indices], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_index\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_idx,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: threshold,\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: left_subtree,\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_subtree\u001b[39m\u001b[38;5;124m'\u001b[39m: right_subtree}\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:19\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Stopping conditions\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;129;01mor\u001b[39;00m num_samples \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split \u001b[38;5;129;01mor\u001b[39;00m num_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_leaf_node(y)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Find best split\u001b[39;00m\n\u001b[0;32m     22\u001b[0m best_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_best_split(X, y)\n",
      "File \u001b[1;32md:\\OneDrive - Université Mohammed VI Polytechnique\\.S2\\CSCI-M123 AI 1 (Data Science)\\Project\\SKL\\mini-sklearn\\AAMM_miniml\\testing\\..\\tree\\DecisionTreeClassifier.py:91\u001b[0m, in \u001b[0;36mDecisionTreeClassifier._create_leaf_node\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_leaf_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m     90\u001b[0m     unique_classes, class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 91\u001b[0m     majority_class \u001b[38;5;241m=\u001b[39m unique_classes[np\u001b[38;5;241m.\u001b[39margmax(class_counts)]\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: majority_class}\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Adnane\\miniconda3\\envs\\ds_ci1\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Adnane\\miniconda3\\envs\\ds_ci1\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tree.DecisionTreeClassifier import DecisionTreeClassifier as MyDecisionTreeClassifier\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy of sklearn decision tree classifier:', accuracy_score(y_test, y_pred))\n",
    "print('MSE of sklearn decision tree classifier:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Train a decision tree classifier\n",
    "my_clf = MyDecisionTreeClassifier(max_depth=5)\n",
    "my_clf.fit(X_train, y_train)\n",
    "y_pred = my_clf.predict(X_test)\n",
    "print('Accuracy of my decision tree classifier:', accuracy_score(y_test, y_pred))\n",
    "print('MSE of my decision tree classifier:', mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_ci1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
